{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from analysis_utils import *\n",
    "from scipy.stats import norm\n",
    "import bayesfit as bf\n",
    "\n",
    "os.chdir('../')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data into Pandas dataframe. To be implemented: run some tests to ensure data quality\n",
    "\n",
    "- does run exist? \n",
    "- does run contain responses?\n",
    "- does run log color_balance and fix_intensity values correctly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of 2AFC Attn Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In psychophysics task participants respond to each trial indicating whether the stimulus presented is more dark or more light.\n",
    "\n",
    "### Scoring convention\n",
    "\n",
    "**LARGE AF:** Response Left (color_balance < 0.5) = Dark; Response Right (color_balance > 0.5) = Light.\n",
    "\n",
    "**SMALL AF:** Response Left (fix color < 0) = Dark; Response Right (fix color > 0) = Light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = os.getcwd()\n",
    "f_names = glob.glob(f\"{wd}/logs/psychophys/*/sub-002*.tsv\")\n",
    "all_logs = load_data(f_names)\n",
    "if 'large_prop' in all_logs.columns:\n",
    "    all_logs.rename(columns = {'large_prop':'color_balance','small_prop':'fix_intensity'}, inplace = True) \n",
    "all_logs[all_logs.event_type == 'response'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = all_logs[(all_logs.event_type == 'response')]\n",
    "# fixed = np.append(np.array(df.color_balance)[1:],[np.array(df.color_balance)[-1]])\n",
    "# df.color_balance = fixed\n",
    "df['correct_s'] = np.nan\n",
    "df['correct_l'] = np.nan\n",
    "\n",
    "# Color task\n",
    "true_left_l = df[(df.color_balance < 0.5) & (df.response == 'left')].index\n",
    "false_left_l = df[(df.color_balance > 0.5) & (df.response == 'left')].index\n",
    "\n",
    "true_right_l = df[(df.color_balance > 0.5) & (df.response == 'right')].index\n",
    "false_right_l = df[(df.color_balance < 0.5) & (df.response == 'right')].index\n",
    "\n",
    "true_left_s = df[(df.fix_intensity < 0.5) & (df.response == 'left')].index\n",
    "false_left_s = df[(df.fix_intensity > 0.5) & (df.response == 'left')].index\n",
    "\n",
    "true_right_s = df[(df.fix_intensity > 0.5) & (df.response == 'right')].index\n",
    "false_right_s = df[(df.fix_intensity < 0.5) & (df.response == 'right')].index\n",
    "\n",
    "df.loc[np.hstack((true_left_l,true_right_l)), 'correct_l'] = 1\n",
    "df.loc[np.hstack((false_left_l,false_right_l)), 'correct_l'] = 0\n",
    "\n",
    "df.loc[np.hstack((true_left_s,true_right_s)), 'correct_s'] = 1\n",
    "df.loc[np.hstack((false_left_s,false_right_s)), 'correct_s'] = 0\n",
    "\n",
    "# df = df.dropna() # drop where color balance = 0.5\n",
    "df.tail()\n",
    "\n",
    "# print(f'Total response \"right\": {sum(df.response == \"left\")} \\\n",
    "#     \\nTotal response \"left\": {sum(df.response == \"right\")} \\\n",
    "#     \\ntrue_left: {len(true_left)/sum(df.fix_intensity < 0)} \\\n",
    "#     \\ntrue_right: {len(true_right)/sum(df.fix_intensity > 0)} \\\n",
    "#     \\nfalse_left: {len(false_left)/sum(df.fix_intensity < 0)} \\\n",
    "#     \\nfalse_right: {len(false_right)/sum(df.fix_intensity > 0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot response light v.s. proportion light. Should increase together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot large AF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l = df[(df.run == '2')]\n",
    "df_l =  df_l.dropna(subset=['correct_l']) # drop where color balance = 0.5\n",
    "difficulties_l = sorted(df_l.color_balance.unique())\n",
    "n_correct_l = []\n",
    "n_trials_l = []\n",
    "resp_light_l = []\n",
    "\n",
    "for diff in difficulties_l:\n",
    "    print(f'Diff: {diff},  \\\n",
    "    \\tn_correct: {len(df_l[(df_l.color_balance == diff) & (df_l.correct_l == 1)])} \\\n",
    "    \\tn_trials: {len(df_l[df_l.color_balance == diff])} \\\n",
    "    \\t% correct {100*len(df_l[(df_l.color_balance == diff) & (df_l.correct_l == 1)])/len(df_l[df_l.color_balance == diff]):.1f}')\n",
    "    n_correct_l.append(len(df_l[(df_l.color_balance == diff) & (df_l.correct_l == 1)]))\n",
    "    n_trials_l.append(len(df_l[df_l.color_balance == diff]))\n",
    "#     print(f'% Light: {diff}, \\t% Response Light {round(len(df[(df.color_balance == diff) & (df.response == \"right\")]) / len(df[df.color_balance == diff]) *100,1)}')\n",
    "    resp_light_l.append(len(df_l[(df_l.color_balance == diff) & (df_l.response == \"right\")]) / len(df_l[df_l.color_balance == diff]))\n",
    "\n",
    "proportions_l = np.array(n_correct_l) / np.array(n_trials_l)\n",
    "\n",
    "largeAFx, largeAFy = abs(np.array(difficulties_l)-0.5), proportions_l\n",
    "          \n",
    "fig, axs = plt.subplots(1,1, figsize=(8,6))\n",
    "\n",
    "axs.set_title('% LargeAF Performance')\n",
    "axs.set_ylabel('Response left')\n",
    "axs.set_ylim(0,1)\n",
    "axs.set_xlabel('% Light')\n",
    "axs.scatter(difficulties_l,resp_light_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot small AF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s = df[(df.run == '1')]\n",
    "df_s =  df_s.dropna(subset=['correct_s']) # drop where fix color = 0\n",
    "difficulties_s = sorted(df_s.fix_intensity.unique())\n",
    "n_correct_s = []\n",
    "n_trials_s = []\n",
    "resp_light_s = []\n",
    "\n",
    "for diff in difficulties_s:\n",
    "    print(f'Diff: {diff} \\\n",
    "          \\tn_correct: {len(df_s[(df_s.fix_intensity == diff) & (df_s.correct_s == 1)])}  \\\n",
    "          \\tn_trials: {len(df_s[df_s.fix_intensity == diff])} \\\n",
    "          \\t% correct: {100*len(df_s[(df_s.fix_intensity == diff) & (df_s.correct_s == 1)])/len(df_s[df_s.fix_intensity == diff]):.1f}')\n",
    "    n_correct_s.append(len(df_s[(df_s.fix_intensity == diff) & (df_s.correct_s == 1)])) \n",
    "    n_trials_s.append(len(df_s[df_s.fix_intensity == diff]))\n",
    "#     print(f'% Light: {diff}, \\t% Response Light {round(len(df[(df.fix_intensity == diff) & (df.response == \"right\")]) / len(df[df.fix_intensity == diff]) *100,1)}')\n",
    "    resp_light_s.append(len(df_s[(df_s.fix_intensity == diff) & (df_s.response == \"right\")]) / len(df_s[df_s.fix_intensity == diff]))\n",
    "\n",
    "proportions_s = np.array(n_correct_s) / np.array(n_trials_s)\n",
    "\n",
    "smallAFx, smallAFy = abs(np.array(difficulties_s)), proportions_s\n",
    "          \n",
    "fig, axs = plt.subplots(1,1, figsize=(8,6))\n",
    "\n",
    "axs.set_title('% SmallAF Performance')\n",
    "axs.set_ylim(0,1)\n",
    "axs.set_ylabel('Response Left')\n",
    "axs.set_xlabel('% Light')\n",
    "axs.scatter(difficulties_s,resp_light_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot difficulty v.s. proportion correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(12,4))\n",
    "\n",
    "axs[0].set_title('SmallAF')\n",
    "axs[0].set_ylabel('Proportion Correct')\n",
    "axs[0].set_ylim(0,1)\n",
    "axs[0].set_xlabel('% Light')\n",
    "axs[0].scatter(smallAFx, smallAFy)\n",
    "\n",
    "axs[1].set_title('LargeAF')\n",
    "axs[1].set_ylabel('Proportion Correct')\n",
    "axs[1].set_ylim(0,1)\n",
    "axs[1].set_xlabel('Distance from 50%')\n",
    "axs[1].scatter(largeAFx, largeAFy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing BayesFit\n",
    "\n",
    "Organize data into `[M X 3 ndarray]` where n is the number of stimulus intensities and the columns are: `[stimulus intensity, N trials correct, and N trials total]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_s = np.vstack((difficulties_s,n_correct_s, n_trials_s)).T\n",
    "\n",
    "# metrics, options = bf.fitmodel(data_s, nafc = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Attn PRF Detection Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_names[0].split('/')[-2].split('_')[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = os.getcwd()\n",
    "f_names = glob.glob(f\"{wd}/logs/*/sub-002*.tsv\")\n",
    "all_logs = load_data(f_names)\n",
    "all_logs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate correct and incorrect responses. Use this to get hits (true positives), misses (false negatives), false alarms (false positives) and correct rejections (true negatives). Once we have these values we can calculate d' and the criterion (c). \n",
    "\n",
    "### Summary per run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psyc, d_primes, large_cor, small_cor = analyse_logs(all_logs)\n",
    "psyc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate d' per difficulty level and plot this to see if two task difficulties are comparable. Unfortunately d' can go to infinity so many points are missing from the performance curves... and we're unsure if they're sigmoidal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = norm.ppf\n",
    "d_primes['d_prime']= Z(d_primes['hit_rate'])- Z(d_primes['fa_rate'])\n",
    "d_primes['criterion'] = -(Z(d_primes['hit_rate']) + Z(d_primes['fa_rate'])) / 2\n",
    "d_primes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_AF = d_primes[d_primes['run'].astype(int) % 2 == 1]\n",
    "small_AF = d_primes[d_primes['run'].astype(int) % 2 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(12,4))\n",
    "\n",
    "ax1.set_title('SmallAF')\n",
    "ax1.scatter(abs(small_AF['difficulty']),small_AF['d_prime'])\n",
    "ax1.set_ylabel('Dprime')\n",
    "\n",
    "ax2.set_title('LargeAF')\n",
    "ax2.scatter(abs(large_AF['difficulty']-0.5),large_AF['d_prime'],color='orange')\n",
    "ax2.set_ylabel('Dprime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use proportion correct to create psychometric curves - although these are not traditional sigmoidal psychometric curves which are designed for 2 alternative forced-choice (2AFC) task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largex, largey = (np.array([i[0] for i in large_cor]), \n",
    "                  np.array([i[1] for i in large_cor]))\n",
    "smallx,smally = (np.array([i[0] for i in small_cor]), \n",
    "                np.array([i[1] for i in small_cor]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2, 2, figsize=(12,8))\n",
    "\n",
    "ax1.set_title('LargeAF_Sigmoid')\n",
    "ax1.scatter([abs(i[0]-0.5) for i in large_cor], [i[1] for i in large_cor])\n",
    "ax1.set_ylabel('Proportion Correct')\n",
    "\n",
    "ax2.set_title('LargeAF_Gauss')\n",
    "ax2.scatter([i[0] for i in large_cor], [i[1] for i in large_cor])\n",
    "ax2.set_ylabel('Proportion Correct')\n",
    "\n",
    "ax3.set_title('SmallAF_Sigmoid')\n",
    "ax3.set_ylim(0,1)\n",
    "ax3.scatter([abs(i[0]-0) for i in small_cor], [i[1] for i in small_cor], color='orange')\n",
    "\n",
    "ax4.set_title('SmallAF_Gauss')\n",
    "ax4.set_ylim(0,1)\n",
    "ax4.scatter([i[0] for i in small_cor], [i[1] for i in small_cor], color='orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a sigmoid function to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use weibull instead????\n",
    "\n",
    "def sigmoid(x, x0, k):\n",
    "    y = 1 / (1 + np.exp(-k*(x-x0)))\n",
    "    return y\n",
    "\n",
    "def inv_sigmoid(y,x0,k):\n",
    "    return x0 - (np.log((1/y)-1)/k)\n",
    "\n",
    "## SMALL AF ##\n",
    "xdata = difficulties_s\n",
    "ydata = resp_light_s\n",
    "\n",
    "popt, pcov = curve_fit(sigmoid, xdata, ydata)\n",
    "print(f'20%: {inv_sigmoid(.2,*popt):.2f} \\\n",
    "      \\n80%: {inv_sigmoid(.8,*popt):.2f}')\n",
    "\n",
    "x = np.linspace(0, 1, 20)\n",
    "y = sigmoid(x, *popt)\n",
    "\n",
    "plt.plot(xdata, ydata, 'o', label='data')\n",
    "plt.title('Small AF')\n",
    "plt.plot(x,y, label='fit')\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('Response Light')\n",
    "plt.xlabel('% Light')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "## LARGE AF ##\n",
    "xdata = difficulties_l\n",
    "ydata = resp_light_l\n",
    "\n",
    "popt, pcov = curve_fit(sigmoid, xdata, ydata)\n",
    "print(f'20%: {inv_sigmoid(.2,*popt):.2f} \\\n",
    "      \\n80%: {inv_sigmoid(.8,*popt):.2f}')\n",
    "\n",
    "x = np.linspace(0, 1, 20)\n",
    "y = sigmoid(x, *popt)\n",
    "\n",
    "plt.plot(xdata, ydata, 'o', label='data')\n",
    "plt.title('Large AF')\n",
    "plt.plot(x,y, label='fit')\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('Response Light')\n",
    "plt.xlabel('% Light')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_inv(0.25,0.52320962,4.85034093)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling psychometric curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pr():\n",
    "    '''\n",
    "    return array of probabilities corresponding to GAUSSIAN cdf\n",
    "    stimuli is range of color_balances / fix intensities\n",
    "    loc\n",
    "    sd / scale\n",
    "    '''\n",
    "    \n",
    "    stim_x = np.arange(0,0.6,0.05)\n",
    "    mu = 0.3\n",
    "    sd = 0.1\n",
    "    \n",
    "    model_pr = norm.cdf(stim_x, mu,sd)\n",
    "    \n",
    "    return stim_x, model_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,pr = model_pr()\n",
    "plt.plot(x, pr, color='k', marker='x', lw=2, ls='--')\n",
    "plt.xlim(0,0.6)\n",
    "plt.ylim(0,1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
